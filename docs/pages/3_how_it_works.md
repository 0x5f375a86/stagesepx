# 运作方式

!> 在开始下面的阅读之前，你需要了解 切割器（cutter）与 分类器（classifier）。stagesepx主要由这两个概念组成。

## 切割器

?> 切割器是 stagesepx 最重要的组成部分，是整个过程能够被自动化的基石。

顾名思义，切割器的功能是将一个视频按照一定的规律切割成多个部分。他负责视频阶段划分与采样，作为数据采集者为其他工具（例如AI模型）提供自动化的数据支持。它应该提供友好的接口或其他形式为外部（包括分类器）提供支持。例如，`pick_and_save`方法完全是为了能够使数据直接被 [keras](https://github.com/keras-team/keras) 利用而设计的。

切割器的定位是预处理，降低其他模块的运作成本及重复度。得到稳定区间之后，我们可以知道视频中有几个稳定阶段、提取稳定阶段对应的帧等等。在此基础上，你可以很轻松地对阶段进行图片采样（例子中为每个阶段采集3张图片，一共有3个稳定阶段，分别名为0、1、2）后保存起来，以备他用（例如AI训练、功能检测等等）：

[![sample_after_cut.png](https://i.loli.net/2019/07/17/5d2ea54271fe256939.png)](https://i.loli.net/2019/07/17/5d2ea54271fe256939.png)

## 分类器

针对上面的例子，分类器应运而生。它主要是加载（在AI分类器上可能是学习）一些分类好的图片，并据此对帧（图片）进行分类。

例如，当加载上述例子中稳定阶段对应的帧后，分类器即可将视频进行帧级别的分类，得到每个阶段的准确耗时。

![stage](../pics/stage.png)

分类器的定位是对视频进行帧级别、高准确度的图片分类，并能够利用采样结果。它应该有不同的存在形态（例如机器学习模型）、以达到不同的分类效果。例如，你可以在前几次视频中用采样得到的数据训练你的AI模型，当它收敛之后在你未来的分析中你就可以直接利用训练好的模型进行分类，而不需要前置的采样过程了。[stagesep2](https://github.com/williamfzc/stagesep2)本质上是一个分类器。

目前，stagesepx官方提供了两种不同类型的分类器，用于处理切割后的结果：

- SVM + HoG分类器在阶段复杂的视频上表现较好，你可以用不同的视频对它进行训练逐步提高它的识别效果，使其足够被用于生产环境；
- 传统的 SSIM 分类器无需训练且较为轻量化，多用于阶段较少、较为简单的视频；

## 设计理念 与 定位

?> stagesepx的定位是，轻量化的、基于图像处理与机器学习的、全自动的视频分析工具。

为了兼顾上述特点（轻量化的AI），我们希望它能够在保证效果的情况下在大多数平台上无痛运行，能够被快速部署，这也意味着它不能有过于苛刻的依赖项（软件与硬件）。除此之外，深度学习需要大量的训练集，而这个量级是单一视频难以提供的。基于这些前提，我们放弃了笨重的深度学习框架而选择了 [sklearn](https://github.com/scikit-learn/scikit-learn)。事实上，对于短视频（30s内）而言，这个包的功能已经非常足够。

当然，**这不意味着你不能使用深度学习来进行分类**，毕竟深度学习的效果理论上要比普通的机器学习算法好得多。你完全可以利用 `cut.py` 得到的结果来训练你的深度学习模型。详见 [这里](/pages/1_where_can_it_be_used?id=as-ai-frontend)。
