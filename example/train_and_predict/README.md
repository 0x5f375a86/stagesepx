# 为你的业务建立稳定的视频分析服务

## 问题

### 为什么分出来的阶段不符合我的预期？

有个前提，人类的视觉感知实际上不是非常灵敏。很多情况下，人类认知的稳定状态实际上并不是真正意义上的稳定。当阈值很高时，这种情况出现的概率会逐步上升，你可能会很奇怪为什么分出来的阶段如此之多。

立竿见影的解决方案是，略微降低阈值，使其不那么敏感。对于大多数情况（例如页面切换）还是非常奏效的，因为这种情况下改变非常剧烈，计算得到的相似度要远低于阈值；而与此同时一些诸如噪音的干扰可以被阈值过滤掉。

如果你遇到的问题是，很多你觉得应该分出来的阶段没有被自动识别出来，那你可以将阈值调高。在这一层面，机器的判定能力要远强于人类。

### 如何定制我的阶段切割结果？

在前面一个问题的基础上，很多人会有进一步的疑问：我认为分出来的阶段客观上符合逻辑，但是我希望自己决定如何分阶段。

当然是可以的。在生产环境的业务上，这种方式是首选的。我也不相信你会有勇气把没有人工干预过的全自动化工具放上正式环境。

首先你需要明白 cutter 与 classifier 是如何运作的（可参见[HOW_IT_WORKS](https://williamfzc.github.io/stagesepx/#/pages/3_how_it_works) 一节）。实际上阶段的划分是由 cutter 来决定的。换言之，我们只需要对 cutter 的行为进行干预，即可进一步控制阶段分割结果。

### 如何自动化地检测结果？

之所以会有这个疑惑，很大程度上是因为 stagesepx 自带了 report 系统，而 [例子](../mini.py)中把处理结果直接渲染成报告展示出来了。

那么这个问题的答案也很简单，你只需要直接处理交给 reporter 的数据就可以了，他们两者并没有耦合关系。

```python
# 分类出来的结果是一个 list，里面包含 ClassifierResult 对象
# 如果你希望这个东西能够接入你的业务，与其他的工具协同，那么光靠后面的报告其实意义不大
# 你可以基于 classify_result 进行定制化开发
for each in classify_result:
    # 它的帧编号
    print(each.frame_id)
    # 它的时间戳
    print(each.timestamp)
    # 它被划分为什么类型
    print(each.stage)
    break
```

具体可以参考 [完整例子](../cut_and_classify.py)

## 实现

这里重点针对 `如何定制我的阶段切割结果？` 来展开，另外两个问题都已经有答案了。

这是一个针对生产环境设计的例子，你可以通过它：

- 了解如何训练一个针对特定业务的模型
    - 利用 cutter 从视频中自动拆分
    - 手工采集
- 如何应用训练好的模型
- 当有业务变更时如何调整你的模型

### 数据采集

#### 利用 cutter 自动从视频中采集

- 录制下多个你的业务场景的操作视频
- 对这些视频进行 cut 操作，得到一系列图片集
- 校验这些图片集的分类是否符合你的预期

如何采集参见 [cut.py](./cut.py)

#### 手动采集

- 自行从视频或其他方式截取一系列图片
- 自行分类，目录结构请参考 cutter 的结果

最后的目录大致形态：

![structure](https://user-images.githubusercontent.com/13421694/64073910-e8a97c80-ccd6-11e9-9847-39c3a4d277c3.png)

### 模型训练

在校验后的训练集上 train 你的模型，并保存。

- 如何训练参见 [train.py](./train.py)
- 如何二次训练参见 [retrain.py](./retrain.py)

当业务出现较大变更时，你可能需要重新训练模型或对原有模型进行二次训练。可以查看 others 中的指引。

### 应用

用稳定模型 predict 视频。

- 如何使用模型参见 [predict.py](./predict.py)

## others

- [关于分类结果修正](https://github.com/williamfzc/stagesepx/issues/48)
